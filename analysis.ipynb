{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907dabc0-3c08-479b-9001-a27b7d19df4f",
   "metadata": {},
   "source": [
    "Attempt to solve the problem in 2 stages. First, try to determine if this is a whale we've seen before. Secondly for each whale we have seen before, match the tail to an id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6937f59b-8987-4e4e-b1eb-8f0c42e2c7fb",
   "metadata": {},
   "source": [
    "# Pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15ecd115-96d7-42f4-b349-4510980cafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df1c5c0-726c-42f8-846b-ab4253456f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4afca5e6-b42d-4928-adc1-5523210237f0",
   "metadata": {},
   "source": [
    "# Add new layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5de347c5-a534-4823-ae27-eb4dd680a953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "      <th>is_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>w_f48451c</td>\n",
       "      <td>existing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>w_c3d896a</td>\n",
       "      <td>existing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>w_20df2c5</td>\n",
       "      <td>existing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image         Id    is_new\n",
       "0  0000e88ab.jpg  w_f48451c  existing\n",
       "1  0001f9222.jpg  w_c3d896a  existing\n",
       "2  00029d126.jpg  w_20df2c5  existing\n",
       "3  00050a15a.jpg  new_whale       new\n",
       "4  0005c1ef8.jpg  new_whale       new"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_map_df = pd.read_csv(os.path.join(\"data\", \"train.csv\"))\n",
    "train_map_df['Id'] = train_map_df['Id'].astype('category')\n",
    "train_map_df['is_new'] = np.where(train_map_df['Id'] == 'new_whale', 'new', 'existing')\n",
    "train_map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c9195d4-c56d-4f37-97ba-5f60d7745de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 224, 224, 3)  0           input_3[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(224, 224, 1))\n",
    "img_conc = Concatenate()([inputs, inputs, inputs]) # repeat the greyscale color channle 3 times to mimic RGB in model\n",
    "\n",
    "\n",
    "base_model = keras.applications.VGG16(\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    input_tensor=img_conc)\n",
    "base_model.summary()\n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = keras.layers.Dense(1)(x) # A Dense classifier with a class for new/existing\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14188bf3-7d29-448c-90d5-71e8107662fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 224, 224, 1)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 513\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6120f82-73a6-436e-897e-2c06ea216b38",
   "metadata": {},
   "source": [
    "# Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8902e845-5436-4151-92cf-af5fb69c5b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have a binary problem (either new or not new)\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True), metrics=[keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbcec5d-4682-4f04-a256-5d89088db3b8",
   "metadata": {},
   "source": [
    "# Augment the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36fa14f1-fd00-42c1-9b67-0d718184ccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        samplewise_center=True,  # set each sample mean to 0\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        validation_split=0.2)  # 80/20 split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9f288d0-b3a5-48ac-980b-9f939e84ed5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20289 validated image filenames belonging to 2 classes.\n",
      "Found 5072 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_it = datagen.flow_from_dataframe(train_map_df,\n",
    "                                       directory=os.path.join('data', 'train'), \n",
    "                                       x_col='Image',\n",
    "                                       y_col='is_new',\n",
    "                                       target_size=(224, 224), \n",
    "                                       color_mode='grayscale', \n",
    "                                       class_mode='binary', \n",
    "                                       batch_size=8,\n",
    "                                       subset='training')\n",
    "valid_it = datagen.flow_from_dataframe(train_map_df,\n",
    "                                       directory=os.path.join('data', 'train'), \n",
    "                                       x_col='Image',\n",
    "                                       y_col='is_new',\n",
    "                                       target_size=(224, 224), \n",
    "                                       color_mode='grayscale', \n",
    "                                       class_mode='binary', \n",
    "                                       batch_size=8,\n",
    "                                       subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41e384ab-26f0-4e4c-badd-8601ee491696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 12s 974ms/step - loss: 1.3607 - binary_accuracy: 0.5208 - val_loss: 1.4910 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 11s 908ms/step - loss: 1.4057 - binary_accuracy: 0.4271 - val_loss: 1.2212 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9464 - binary_accuracy: 0.5417 - val_loss: 1.1700 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0392 - binary_accuracy: 0.5833 - val_loss: 0.7695 - val_binary_accuracy: 0.7500\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.9477 - binary_accuracy: 0.6042 - val_loss: 1.0145 - val_binary_accuracy: 0.5938\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.2346 - binary_accuracy: 0.4896 - val_loss: 0.9364 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.8404 - binary_accuracy: 0.6667 - val_loss: 1.1416 - val_binary_accuracy: 0.7188\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0041 - binary_accuracy: 0.5938 - val_loss: 1.2300 - val_binary_accuracy: 0.5625\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 15s 1s/step - loss: 1.0610 - binary_accuracy: 0.5833 - val_loss: 0.7773 - val_binary_accuracy: 0.6875\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.9629 - binary_accuracy: 0.5312 - val_loss: 0.8115 - val_binary_accuracy: 0.5938\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 15s 1s/step - loss: 1.0068 - binary_accuracy: 0.5833 - val_loss: 1.0185 - val_binary_accuracy: 0.5312\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.7573 - binary_accuracy: 0.6458 - val_loss: 0.9373 - val_binary_accuracy: 0.5312\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.8194 - binary_accuracy: 0.6250 - val_loss: 1.0185 - val_binary_accuracy: 0.5625\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 15s 1s/step - loss: 1.0789 - binary_accuracy: 0.5521 - val_loss: 1.1845 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.8731 - binary_accuracy: 0.5955 - val_loss: 1.0268 - val_binary_accuracy: 0.5625\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.9707 - binary_accuracy: 0.5417 - val_loss: 1.3079 - val_binary_accuracy: 0.5625\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.8078 - binary_accuracy: 0.6146 - val_loss: 1.0987 - val_binary_accuracy: 0.5938\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 1.0218 - binary_accuracy: 0.5625 - val_loss: 0.9734 - val_binary_accuracy: 0.5938\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.8956 - binary_accuracy: 0.6354 - val_loss: 1.1018 - val_binary_accuracy: 0.4688\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.9675 - binary_accuracy: 0.5208 - val_loss: 0.4703 - val_binary_accuracy: 0.8125\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.8571 - binary_accuracy: 0.6042 - val_loss: 0.6593 - val_binary_accuracy: 0.7500\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.8299 - binary_accuracy: 0.6250 - val_loss: 0.7971 - val_binary_accuracy: 0.7188\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.8260 - binary_accuracy: 0.6042 - val_loss: 0.9355 - val_binary_accuracy: 0.5625\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.7933 - binary_accuracy: 0.6354 - val_loss: 0.9267 - val_binary_accuracy: 0.5625\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.8186 - binary_accuracy: 0.6458 - val_loss: 1.1270 - val_binary_accuracy: 0.4688\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.7823 - binary_accuracy: 0.6562 - val_loss: 0.8537 - val_binary_accuracy: 0.6875\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.8615 - binary_accuracy: 0.5833 - val_loss: 1.1973 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.6453 - binary_accuracy: 0.6875 - val_loss: 0.9028 - val_binary_accuracy: 0.5938\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.7210 - binary_accuracy: 0.6146 - val_loss: 0.8397 - val_binary_accuracy: 0.6875\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.8214 - binary_accuracy: 0.6562 - val_loss: 0.9747 - val_binary_accuracy: 0.5625\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.9187 - binary_accuracy: 0.5833 - val_loss: 0.7138 - val_binary_accuracy: 0.6875\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.6436 - binary_accuracy: 0.7083 - val_loss: 1.0609 - val_binary_accuracy: 0.5938\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.9276 - binary_accuracy: 0.6458 - val_loss: 0.8022 - val_binary_accuracy: 0.5938\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.9656 - binary_accuracy: 0.6667 - val_loss: 1.0744 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.7903 - binary_accuracy: 0.6979 - val_loss: 1.0867 - val_binary_accuracy: 0.5625\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.8071 - binary_accuracy: 0.5833 - val_loss: 0.8194 - val_binary_accuracy: 0.5625\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.8821 - binary_accuracy: 0.5625 - val_loss: 0.9196 - val_binary_accuracy: 0.6562\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.7362 - binary_accuracy: 0.6875 - val_loss: 1.0579 - val_binary_accuracy: 0.5312\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.7727 - binary_accuracy: 0.6562 - val_loss: 0.5666 - val_binary_accuracy: 0.7188\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.9254 - binary_accuracy: 0.5625 - val_loss: 0.6090 - val_binary_accuracy: 0.6562\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.6852 - binary_accuracy: 0.6875 - val_loss: 0.6821 - val_binary_accuracy: 0.6562\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.6939 - binary_accuracy: 0.6458 - val_loss: 0.5717 - val_binary_accuracy: 0.7500\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.8101 - binary_accuracy: 0.6146 - val_loss: 0.9833 - val_binary_accuracy: 0.5312\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.6880 - binary_accuracy: 0.6979 - val_loss: 0.7745 - val_binary_accuracy: 0.6562\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.8380 - binary_accuracy: 0.6042 - val_loss: 1.1079 - val_binary_accuracy: 0.6250\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.8005 - binary_accuracy: 0.5312 - val_loss: 0.9460 - val_binary_accuracy: 0.6250\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.9105 - binary_accuracy: 0.5625 - val_loss: 0.6073 - val_binary_accuracy: 0.6875\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.6126 - binary_accuracy: 0.6979 - val_loss: 0.6896 - val_binary_accuracy: 0.6875\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.7733 - binary_accuracy: 0.5729 - val_loss: 0.9079 - val_binary_accuracy: 0.5625\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.7843 - binary_accuracy: 0.5833 - val_loss: 0.8120 - val_binary_accuracy: 0.6562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x192cc257b80>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_it, steps_per_epoch=12, validation_data=valid_it, validation_steps=4, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca4e8d1a-a7e5-4c01-a760-d09ad693deaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "      <th>is_new</th>\n",
       "      <th>full_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>w_f48451c</td>\n",
       "      <td>existing</td>\n",
       "      <td>data\\train\\0000e88ab.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>w_c3d896a</td>\n",
       "      <td>existing</td>\n",
       "      <td>data\\train\\0001f9222.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>w_20df2c5</td>\n",
       "      <td>existing</td>\n",
       "      <td>data\\train\\00029d126.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "      <td>new</td>\n",
       "      <td>data\\train\\00050a15a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "      <td>new</td>\n",
       "      <td>data\\train\\0005c1ef8.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image         Id    is_new                 full_path\n",
       "0  0000e88ab.jpg  w_f48451c  existing  data\\train\\0000e88ab.jpg\n",
       "1  0001f9222.jpg  w_c3d896a  existing  data\\train\\0001f9222.jpg\n",
       "2  00029d126.jpg  w_20df2c5  existing  data\\train\\00029d126.jpg\n",
       "3  00050a15a.jpg  new_whale       new  data\\train\\00050a15a.jpg\n",
       "4  0005c1ef8.jpg  new_whale       new  data\\train\\0005c1ef8.jpg"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_map_df['full_path'] = train_map_df['Image'].apply(lambda x: os.path.join('data', 'train', x))\n",
    "train_map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eae25e9e-a4cb-4b76-9645-eeecf5acb5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "      <th>is_new</th>\n",
       "      <th>full_path</th>\n",
       "      <th>predicted_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>w_f48451c</td>\n",
       "      <td>existing</td>\n",
       "      <td>data\\train\\0000e88ab.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>w_c3d896a</td>\n",
       "      <td>existing</td>\n",
       "      <td>data\\train\\0001f9222.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>w_20df2c5</td>\n",
       "      <td>existing</td>\n",
       "      <td>data\\train\\00029d126.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "      <td>new</td>\n",
       "      <td>data\\train\\00050a15a.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "      <td>new</td>\n",
       "      <td>data\\train\\0005c1ef8.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25356</th>\n",
       "      <td>ffef89eed.jpg</td>\n",
       "      <td>w_9c506f6</td>\n",
       "      <td>existing</td>\n",
       "      <td>data\\train\\ffef89eed.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25357</th>\n",
       "      <td>fff7faf61.jpg</td>\n",
       "      <td>w_9cf0388</td>\n",
       "      <td>existing</td>\n",
       "      <td>data\\train\\fff7faf61.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25358</th>\n",
       "      <td>fff9002e0.jpg</td>\n",
       "      <td>w_bd1c3d5</td>\n",
       "      <td>existing</td>\n",
       "      <td>data\\train\\fff9002e0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25359</th>\n",
       "      <td>fffcde6fe.jpg</td>\n",
       "      <td>w_9f30885</td>\n",
       "      <td>existing</td>\n",
       "      <td>data\\train\\fffcde6fe.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25360</th>\n",
       "      <td>fffde072b.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "      <td>new</td>\n",
       "      <td>data\\train\\fffde072b.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25361 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Image         Id    is_new                 full_path  \\\n",
       "0      0000e88ab.jpg  w_f48451c  existing  data\\train\\0000e88ab.jpg   \n",
       "1      0001f9222.jpg  w_c3d896a  existing  data\\train\\0001f9222.jpg   \n",
       "2      00029d126.jpg  w_20df2c5  existing  data\\train\\00029d126.jpg   \n",
       "3      00050a15a.jpg  new_whale       new  data\\train\\00050a15a.jpg   \n",
       "4      0005c1ef8.jpg  new_whale       new  data\\train\\0005c1ef8.jpg   \n",
       "...              ...        ...       ...                       ...   \n",
       "25356  ffef89eed.jpg  w_9c506f6  existing  data\\train\\ffef89eed.jpg   \n",
       "25357  fff7faf61.jpg  w_9cf0388  existing  data\\train\\fff7faf61.jpg   \n",
       "25358  fff9002e0.jpg  w_bd1c3d5  existing  data\\train\\fff9002e0.jpg   \n",
       "25359  fffcde6fe.jpg  w_9f30885  existing  data\\train\\fffcde6fe.jpg   \n",
       "25360  fffde072b.jpg  new_whale       new  data\\train\\fffde072b.jpg   \n",
       "\n",
       "       predicted_new  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  1  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "25356              0  \n",
       "25357              1  \n",
       "25358              1  \n",
       "25359              1  \n",
       "25360              1  \n",
       "\n",
       "[25361 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image as image_utils\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "predictions = []\n",
    "paths = train_map_df['Image']\n",
    "\n",
    "def make_prediction(image_path):\n",
    "    image = image_utils.load_img(os.path.join('data', 'train', image_path), target_size=(224, 224), color_mode=\"grayscale\")\n",
    "    image = image_utils.img_to_array(image)\n",
    "    image = image.reshape(1,224,224)\n",
    "    image = preprocess_input(image)\n",
    "    preds = model.predict(image)\n",
    "    return preds[0][0]\n",
    "\n",
    "for id in train_map_df['Image']:\n",
    "    predictions.append(0 if make_prediction(id) < 0 else 1)\n",
    "\n",
    "train_map_df['predicted_new'] = pd.Series(predictions)\n",
    "train_map_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4251686c-bfcf-418e-9ef2-a7b14572320f",
   "metadata": {},
   "source": [
    "Secondary model to id existing whales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a03a652-7c34-459d-94df-4914e664dcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 224, 224, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 224, 224, 3)  0           input_4[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Found 12558 validated image filenames belonging to 5004 classes.\n",
      "Found 3139 validated image filenames belonging to 5004 classes.\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 10.3798 - categorical_accuracy: 0.0000e+00 - val_loss: 10.4338 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 10.9686 - categorical_accuracy: 0.0208 - val_loss: 10.3983 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 24s 2s/step - loss: 11.4221 - categorical_accuracy: 0.0208 - val_loss: 11.2062 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 31s 3s/step - loss: 11.6890 - categorical_accuracy: 0.0104 - val_loss: 12.5255 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 30s 2s/step - loss: 12.0502 - categorical_accuracy: 0.0104 - val_loss: 12.9097 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 20s 2s/step - loss: 12.2998 - categorical_accuracy: 0.0000e+00 - val_loss: 13.5330 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 12.8078 - categorical_accuracy: 0.0208 - val_loss: 13.4225 - val_categorical_accuracy: 0.0312\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 12.5352 - categorical_accuracy: 0.0312 - val_loss: 13.0826 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 13.2451 - categorical_accuracy: 0.0208 - val_loss: 13.2912 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 13.6453 - categorical_accuracy: 0.0417 - val_loss: 13.6230 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 14.4043 - categorical_accuracy: 0.0312 - val_loss: 14.6611 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 25s 2s/step - loss: 13.6745 - categorical_accuracy: 0.0104 - val_loss: 14.5247 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 25s 2s/step - loss: 13.1477 - categorical_accuracy: 0.0208 - val_loss: 14.5833 - val_categorical_accuracy: 0.0312\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 24s 2s/step - loss: 13.8754 - categorical_accuracy: 0.0208 - val_loss: 14.7651 - val_categorical_accuracy: 0.0312\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 24s 2s/step - loss: 13.6795 - categorical_accuracy: 0.0312 - val_loss: 13.6786 - val_categorical_accuracy: 0.0312\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 13.2585 - categorical_accuracy: 0.0208 - val_loss: 13.0517 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 13.9564 - categorical_accuracy: 0.0312 - val_loss: 14.5569 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 12.2895 - categorical_accuracy: 0.1042 - val_loss: 13.1096 - val_categorical_accuracy: 0.0312\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 12.8329 - categorical_accuracy: 0.0729 - val_loss: 16.8104 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 24s 2s/step - loss: 14.7659 - categorical_accuracy: 0.0521 - val_loss: 12.7349 - val_categorical_accuracy: 0.0938\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 30s 3s/step - loss: 12.6870 - categorical_accuracy: 0.0833 - val_loss: 15.5474 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 34s 3s/step - loss: 13.9254 - categorical_accuracy: 0.0312 - val_loss: 16.5111 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 33s 3s/step - loss: 13.3025 - categorical_accuracy: 0.0729 - val_loss: 15.6047 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 32s 3s/step - loss: 11.5717 - categorical_accuracy: 0.1042 - val_loss: 14.5357 - val_categorical_accuracy: 0.0312\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 14.0708 - categorical_accuracy: 0.0208 - val_loss: 15.8141 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 24s 2s/step - loss: 13.4192 - categorical_accuracy: 0.0312 - val_loss: 15.5053 - val_categorical_accuracy: 0.0312\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 13.5652 - categorical_accuracy: 0.0417 - val_loss: 16.0122 - val_categorical_accuracy: 0.0312\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 24s 2s/step - loss: 13.2169 - categorical_accuracy: 0.0833 - val_loss: 14.7030 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 24s 2s/step - loss: 11.9358 - categorical_accuracy: 0.0729 - val_loss: 14.6400 - val_categorical_accuracy: 0.0312\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 28s 2s/step - loss: 12.8664 - categorical_accuracy: 0.0938 - val_loss: 14.2009 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 20s 2s/step - loss: 12.2661 - categorical_accuracy: 0.0312 - val_loss: 15.7668 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 21s 2s/step - loss: 14.7960 - categorical_accuracy: 0.0312 - val_loss: 16.5241 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 21s 2s/step - loss: 15.8647 - categorical_accuracy: 0.0521 - val_loss: 17.6564 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 14.9640 - categorical_accuracy: 0.0729 - val_loss: 13.5904 - val_categorical_accuracy: 0.0312\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 13.7441 - categorical_accuracy: 0.0729 - val_loss: 14.9563 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 13.4855 - categorical_accuracy: 0.0625 - val_loss: 13.6277 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 12.7368 - categorical_accuracy: 0.0521 - val_loss: 15.6710 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 12.7631 - categorical_accuracy: 0.0417 - val_loss: 15.2108 - val_categorical_accuracy: 0.0312\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 24s 2s/step - loss: 13.8228 - categorical_accuracy: 0.0625 - val_loss: 16.9259 - val_categorical_accuracy: 0.0625\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 11.9154 - categorical_accuracy: 0.1042 - val_loss: 16.6623 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 13.6216 - categorical_accuracy: 0.0417 - val_loss: 15.5757 - val_categorical_accuracy: 0.0312\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 23s 2s/step - loss: 13.4855 - categorical_accuracy: 0.0938 - val_loss: 15.8287 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 26s 2s/step - loss: 12.8883 - categorical_accuracy: 0.1042 - val_loss: 13.1099 - val_categorical_accuracy: 0.0312\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 26s 2s/step - loss: 14.7142 - categorical_accuracy: 0.0625 - val_loss: 14.8957 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 26s 2s/step - loss: 13.3832 - categorical_accuracy: 0.0625 - val_loss: 14.7172 - val_categorical_accuracy: 0.0312\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 13.6143 - categorical_accuracy: 0.0521 - val_loss: 14.3075 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 12.6070 - categorical_accuracy: 0.0625 - val_loss: 15.7485 - val_categorical_accuracy: 0.0312\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 22s 2s/step - loss: 11.6053 - categorical_accuracy: 0.1146 - val_loss: 14.6471 - val_categorical_accuracy: 0.0312\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 27s 2s/step - loss: 12.5074 - categorical_accuracy: 0.0833 - val_loss: 16.0218 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 24s 2s/step - loss: 13.6413 - categorical_accuracy: 0.0638 - val_loss: 18.2102 - val_categorical_accuracy: 0.0312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x192dab1d970>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_2 = keras.Input(shape=(224, 224, 1))\n",
    "img_conc_2 = Concatenate()([inputs_2, inputs_2, inputs_2])  \n",
    "x_2 = base_model(inputs_2, training=False)\n",
    "x_2 = keras.layers.GlobalAveragePooling2D()(x_2)\n",
    "outputs_2 = keras.layers.Dense(len(train_map_df['Id'].unique())-1)(x_2) # A Dense classifier with a each class from our training set excluded new_whale\n",
    "\n",
    "\n",
    "base_model_2 = keras.applications.VGG16(\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    input_tensor=img_conc_2)\n",
    "\n",
    "base_model_2.summary()\n",
    "base_model_2.trainable = False\n",
    "\n",
    "model_2 = keras.Model(inputs_2, outputs_2)\n",
    "\n",
    "# we have a categorical problem so need to use CategoricalCrossentropy and CategoricalAccuracy\n",
    "model_2.compile(loss=keras.losses.CategoricalCrossentropy(from_logits=True), metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "datagen_2 = ImageDataGenerator(\n",
    "        samplewise_center=True,  # set each sample mean to 0\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        validation_split=0.2)  # 80/20 split train/test\n",
    "\n",
    "train_it_2 = datagen.flow_from_dataframe(train_map_df[train_map_df['is_new'] == 'existing'],\n",
    "                                       directory=os.path.join('data', 'train'), \n",
    "                                       x_col='Image',\n",
    "                                       y_col='Id',\n",
    "                                       target_size=(224, 224), \n",
    "                                       color_mode='grayscale', \n",
    "                                       class_mode='categorical', \n",
    "                                       batch_size=8,\n",
    "                                       subset='training')\n",
    "valid_it_2 = datagen.flow_from_dataframe(train_map_df[train_map_df['is_new'] == 'existing'],\n",
    "                                       directory=os.path.join('data', 'train'), \n",
    "                                       x_col='Image',\n",
    "                                       y_col='Id',\n",
    "                                       target_size=(224, 224), \n",
    "                                       color_mode='grayscale', \n",
    "                                       class_mode='categorical', \n",
    "                                       batch_size=8,\n",
    "                                       subset='validation')\n",
    "model_2.fit(train_it_2, steps_per_epoch=12, validation_data=valid_it_2, validation_steps=4, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b8b0c7-56bb-4d3c-b6c4-502c34be20d9",
   "metadata": {},
   "source": [
    "Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0147daa4-0cc3-4042-b4c5-8cd9d459d0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "      <th>is_new</th>\n",
       "      <th>full_path</th>\n",
       "      <th>predicted_new</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>w_f48451c</td>\n",
       "      <td>existing</td>\n",
       "      <td>data\\train\\0000e88ab.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>w_c3d896a</td>\n",
       "      <td>existing</td>\n",
       "      <td>data\\train\\0001f9222.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>w_20df2c5</td>\n",
       "      <td>existing</td>\n",
       "      <td>data\\train\\00029d126.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "      <td>new</td>\n",
       "      <td>data\\train\\00050a15a.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "      <td>new</td>\n",
       "      <td>data\\train\\0005c1ef8.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25356</th>\n",
       "      <td>ffef89eed.jpg</td>\n",
       "      <td>w_9c506f6</td>\n",
       "      <td>existing</td>\n",
       "      <td>data\\train\\ffef89eed.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>w_4488584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25357</th>\n",
       "      <td>fff7faf61.jpg</td>\n",
       "      <td>w_9cf0388</td>\n",
       "      <td>existing</td>\n",
       "      <td>data\\train\\fff7faf61.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25358</th>\n",
       "      <td>fff9002e0.jpg</td>\n",
       "      <td>w_bd1c3d5</td>\n",
       "      <td>existing</td>\n",
       "      <td>data\\train\\fff9002e0.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25359</th>\n",
       "      <td>fffcde6fe.jpg</td>\n",
       "      <td>w_9f30885</td>\n",
       "      <td>existing</td>\n",
       "      <td>data\\train\\fffcde6fe.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25360</th>\n",
       "      <td>fffde072b.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "      <td>new</td>\n",
       "      <td>data\\train\\fffde072b.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25361 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Image         Id    is_new                 full_path  \\\n",
       "0      0000e88ab.jpg  w_f48451c  existing  data\\train\\0000e88ab.jpg   \n",
       "1      0001f9222.jpg  w_c3d896a  existing  data\\train\\0001f9222.jpg   \n",
       "2      00029d126.jpg  w_20df2c5  existing  data\\train\\00029d126.jpg   \n",
       "3      00050a15a.jpg  new_whale       new  data\\train\\00050a15a.jpg   \n",
       "4      0005c1ef8.jpg  new_whale       new  data\\train\\0005c1ef8.jpg   \n",
       "...              ...        ...       ...                       ...   \n",
       "25356  ffef89eed.jpg  w_9c506f6  existing  data\\train\\ffef89eed.jpg   \n",
       "25357  fff7faf61.jpg  w_9cf0388  existing  data\\train\\fff7faf61.jpg   \n",
       "25358  fff9002e0.jpg  w_bd1c3d5  existing  data\\train\\fff9002e0.jpg   \n",
       "25359  fffcde6fe.jpg  w_9f30885  existing  data\\train\\fffcde6fe.jpg   \n",
       "25360  fffde072b.jpg  new_whale       new  data\\train\\fffde072b.jpg   \n",
       "\n",
       "       predicted_new predictions  \n",
       "0                  1   new_whale  \n",
       "1                  1   new_whale  \n",
       "2                  1   new_whale  \n",
       "3                  1   new_whale  \n",
       "4                  1   new_whale  \n",
       "...              ...         ...  \n",
       "25356              0   w_4488584  \n",
       "25357              1   new_whale  \n",
       "25358              1   new_whale  \n",
       "25359              1   new_whale  \n",
       "25360              1   new_whale  \n",
       "\n",
       "[25361 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "existing_ids = train_map_df['Id'].unique()\n",
    "\n",
    "for image, predicted_new in zip(train_map_df['Image'], train_map_df['predicted_new']):\n",
    "    if predicted_new == 1:\n",
    "        predictions.append('new_whale')\n",
    "    else:\n",
    "        image = image_utils.load_img(os.path.join('data', 'train', image), target_size=(224, 224), color_mode=\"grayscale\")\n",
    "        image = image_utils.img_to_array(image)\n",
    "        image = image.reshape(1,224,224)\n",
    "        image = preprocess_input(image)\n",
    "        preds = model_2.predict(image)\n",
    "        predictions.append(existing_ids[np.argmax(preds)])\n",
    "        \n",
    "train_map_df['predictions'] = pd.Series(predictions)\n",
    "train_map_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69b601b0-2b50-4fc8-9a58-74b687c90b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 0.2943890225148851\n"
     ]
    }
   ],
   "source": [
    "print('Total accuracy: ' + str(np.sum(train_map_df['Id'] == train_map_df['predictions']) / len(train_map_df['Id'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
